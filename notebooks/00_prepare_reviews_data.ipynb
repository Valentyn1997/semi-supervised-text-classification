{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unlabelled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_csv('../data/REVIEWS - raw/6_arg_extraction_t_prediction_t_confidence-2.csv')\n",
    "full_df['id'] = full_df.conference + full_df.paper_id.astype(str) +\\\n",
    "    '_' + full_df.review_id.astype(str) + '_' + full_df.sentence_id.astype(str)\n",
    "full_df['annotation'] = 'UNL'\n",
    "full_df = full_df[['id', 'sentence', 'annotation']]\n",
    "full_df['topic'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>annotation</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>graph201_1_0</td>\n",
       "      <td>\"I have reviewed this paper earlier as a SIGGR...</td>\n",
       "      <td>UNL</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>graph201_1_1</td>\n",
       "      <td>The paper presents a novel method based on dee...</td>\n",
       "      <td>UNL</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>graph201_1_2</td>\n",
       "      <td>As a representation for the 3D shape, the auth...</td>\n",
       "      <td>UNL</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>graph201_1_3</td>\n",
       "      <td>The model has been trained on a tiny dataset (...</td>\n",
       "      <td>UNL</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>graph201_1_4</td>\n",
       "      <td>The architecture of the network is based on an...</td>\n",
       "      <td>UNL</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257811</th>\n",
       "      <td>iclr202213_3_14</td>\n",
       "      <td>Your grammar is backwards.</td>\n",
       "      <td>UNL</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257812</th>\n",
       "      <td>iclr202213_3_15</td>\n",
       "      <td>The question you are trying to express is \"bia...</td>\n",
       "      <td>UNL</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257813</th>\n",
       "      <td>iclr202213_3_16</td>\n",
       "      <td>So heading should be \"to what inside the envir...</td>\n",
       "      <td>UNL</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257814</th>\n",
       "      <td>iclr202213_3_17</td>\n",
       "      <td>--&gt; idk that this is that surprising, it was k...</td>\n",
       "      <td>UNL</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257815</th>\n",
       "      <td>iclr202213_3_18</td>\n",
       "      <td>So maybe rephrase this sentence. \"</td>\n",
       "      <td>UNL</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>257816 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                           sentence  \\\n",
       "0          graph201_1_0  \"I have reviewed this paper earlier as a SIGGR...   \n",
       "1          graph201_1_1  The paper presents a novel method based on dee...   \n",
       "2          graph201_1_2  As a representation for the 3D shape, the auth...   \n",
       "3          graph201_1_3  The model has been trained on a tiny dataset (...   \n",
       "4          graph201_1_4  The architecture of the network is based on an...   \n",
       "...                 ...                                                ...   \n",
       "257811  iclr202213_3_14                         Your grammar is backwards.   \n",
       "257812  iclr202213_3_15  The question you are trying to express is \"bia...   \n",
       "257813  iclr202213_3_16  So heading should be \"to what inside the envir...   \n",
       "257814  iclr202213_3_17  --> idk that this is that surprising, it was k...   \n",
       "257815  iclr202213_3_18                 So maybe rephrase this sentence. \"   \n",
       "\n",
       "       annotation topic  \n",
       "0             UNL        \n",
       "1             UNL        \n",
       "2             UNL        \n",
       "3             UNL        \n",
       "4             UNL        \n",
       "...           ...   ...  \n",
       "257811        UNL        \n",
       "257812        UNL        \n",
       "257813        UNL        \n",
       "257814        UNL        \n",
       "257815        UNL        \n",
       "\n",
       "[257816 rows x 4 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df[['annotation', 'sentence', 'topic']].to_csv('../data/REVIEWS - clean/in-topic/unlabelled.tsv', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labelled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_df = pd.read_csv('../data/REVIEWS - raw/sentences_just_one_position.csv', header=None, \n",
    "                          names=['id', 'sentence', 'annotation'], sep='\\t')\n",
    "label_dict = {\n",
    "    ' NEG': 'Argument_against',\n",
    "    ' POS': 'Argument_for',\n",
    "    ' NA': 'NoArgument'\n",
    "}\n",
    "labelled_df['topic'] = ''\n",
    "labelled_df['annotation'] = labelled_df['annotation'].map(lambda x: label_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence_x</th>\n",
       "      <th>annotation_x</th>\n",
       "      <th>topic_x</th>\n",
       "      <th>sentence_y</th>\n",
       "      <th>annotation_y</th>\n",
       "      <th>topic_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, sentence_x, annotation_x, topic_x, sentence_y, annotation_y, topic_y]\n",
       "Index: []"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Non-overlap check\n",
    "pd.merge(full_df, labelled_df, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Argument_against    640\n",
       "NoArgument          558\n",
       "Argument_for        203\n",
       "Name: annotation, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_df.annotation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = np.split(labelled_df.sample(frac=1, random_state=42), \n",
    "                                     [int(.6*len(labelled_df)), int(.8*len(labelled_df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(840, 280, 281)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df), len(val_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5995717344753747, 0.1998572448251249, 0.20057102069950036)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)/len(labelled_df), len(val_df)/len(labelled_df), len(test_df)/len(labelled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[['annotation', 'sentence', 'topic']].to_csv('../data/REVIEWS - clean/in-topic/train.tsv', sep='\\t', index=False)\n",
    "val_df[['annotation', 'sentence', 'topic']].to_csv('../data/REVIEWS - clean/in-topic/val.tsv', sep='\\t', index=False)\n",
    "test_df[['annotation', 'sentence', 'topic']].to_csv('../data/REVIEWS - clean/in-topic/test.tsv', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
